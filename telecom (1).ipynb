{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_recall_curve\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# -----------------------------\n",
        "# 1. LOAD & CLEAN DATA\n",
        "# -----------------------------\n",
        "df = pd.read_csv('datset.csv')\n",
        "\n",
        "\n",
        "df.drop('customerID', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "df.replace(' ', np.nan, inplace=True)\n",
        "\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "print(\"Initial Data Shape:\", df.shape)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. TARGET & FEATURES\n",
        "# -----------------------------\n",
        "y = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "X = df.drop('Churn', axis=1)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. FEATURE ANALYSIS & SELECTION\n",
        "# -----------------------------\n",
        "\n",
        "irrelevant_cols = ['customerID']  # already dropped\n",
        "X = X.drop(columns=irrelevant_cols, errors='ignore')\n",
        "\n",
        "# Separate numeric and categorical columns\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Correlation with target (only numeric features)\n",
        "corr_with_target = X[numeric_cols].copy()\n",
        "corr_with_target['Churn'] = y\n",
        "corr_matrix = corr_with_target.corr()\n",
        "target_corr = corr_matrix['Churn'].drop('Churn')\n",
        "\n",
        "# Keep numeric features that have abs(corr) > threshold\n",
        "corr_threshold = 0.05  # small threshold to remove almost useless features\n",
        "good_numeric_features = target_corr[abs(target_corr) > corr_threshold].index.tolist()\n",
        "\n",
        "print(\"Selected numeric features based on target correlation:\", good_numeric_features)\n",
        "\n",
        "# Keep only selected numeric features\n",
        "X_numeric = X[good_numeric_features]\n",
        "\n",
        "# -----------------------------\n",
        "# 4. ONE-HOT ENCODE CATEGORICAL FEATURES\n",
        "# -----------------------------\n",
        "X_categorical = pd.get_dummies(X[categorical_cols], drop_first=True)\n",
        "\n",
        "# Combine numeric + categorical\n",
        "X_final = pd.concat([X_numeric, X_categorical], axis=1)\n",
        "\n",
        "print(\"Final Feature Shape:\", X_final.shape)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. TRAIN-TEST SPLIT\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_final, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 6. SMOTE OVERSAMPLING\n",
        "# -----------------------------\n",
        "print(\"Before SMOTE:\", np.bincount(y_train))\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"After SMOTE:\", np.bincount(y_train_res))\n",
        "\n",
        "# -----------------------------\n",
        "# 7. SCALING\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# 8. XGBOOST MODEL\n",
        "# -----------------------------\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "# -----------------------------\n",
        "# 9. THRESHOLD OPTIMIZATION\n",
        "# -----------------------------\n",
        "y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "best_f1 = 0\n",
        "best_threshold = 0.5\n",
        "\n",
        "prec, rec, thresholds = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_t = (y_proba >= t).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred_t)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_threshold = t\n",
        "\n",
        "print(\"\\nBest Threshold:\", best_threshold)\n",
        "print(\"Best F1 Score:\", best_f1)\n",
        "\n",
        "# -----------------------------\n",
        "# 10. FINAL EVALUATION\n",
        "# -----------------------------\n",
        "y_pred_final = (y_proba >= best_threshold).astype(int)\n",
        "\n",
        "print(\"\\n--- XGBoost Performance (Threshold Optimized) ---\")\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_final))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_final))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbDv0JE1yEQ-",
        "outputId": "295d3cea-a7dd-47eb-e018-36088a013e9f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Shape: (7043, 20)\n",
            "Selected numeric features based on target correlation: ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
            "Final Feature Shape: (7043, 30)\n",
            "Before SMOTE: [4139 1495]\n",
            "After SMOTE: [4139 4139]\n",
            "\n",
            "Best Threshold: 0.33631936\n",
            "Best F1 Score: 0.6236786469344608\n",
            "\n",
            "--- XGBoost Performance (Threshold Optimized) ---\n",
            "F1 Score: 0.6236786469344608\n",
            "ROC AUC: 0.8272985610581518\n",
            "Confusion Matrix:\n",
            "[[758 277]\n",
            " [ 79 295]]\n"
          ]
        }
      ]
    }
  ]
}